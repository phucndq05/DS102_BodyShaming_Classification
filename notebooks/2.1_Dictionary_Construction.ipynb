{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a00deca",
   "metadata": {},
   "source": [
    "## Cell 1: Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197c266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pyvi import ViTokenizer\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f7e7d",
   "metadata": {},
   "source": [
    "## Cell 2: Xử lý Blank và Lọc dữ liệu (Quan trọng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ea7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Đang lọc dữ liệu thô...\n",
      "Đã lưu file sạch tại: ../data/raw/dataset_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn tương đối từ thư mục notebooks/\n",
    "input_path = '../data/raw/dataset_raw.csv'\n",
    "clean_path = '../data/raw/dataset_filtered.csv'\n",
    "\n",
    "print(\"1. Đang lọc dữ liệu thô...\")\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Logic xóa dòng Null Label, cmt rỗng\n",
    "df_clean = df.dropna(subset=['label', 'comment_text'])\n",
    "df_clean = df_clean[df_clean['comment_text'].astype(str).str.strip() != '']\n",
    "df_clean.to_csv(clean_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu file sạch tại: {clean_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e04675",
   "metadata": {},
   "source": [
    "## Cell 3: Khảo sát độ phủ (Step 1)\n",
    "Mục đích: Chạy đoạn này để nhìn bảng kết quả, xem ở Top bao nhiêu thì độ phủ đạt >70% (Điểm bão hòa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dd84a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc dữ liệu và tách từ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 6124/6124 [00:00<00:00, 24430.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top N từ   | Độ phủ (%)     \n",
      "------------------------------\n",
      "100        | 44.99%\n",
      "200        | 57.43%\n",
      "500        | 72.60%\n",
      "1000       | 82.17%\n",
      "2000       | 90.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Đọc và Tách từ\n",
    "print(\"Đang đọc dữ liệu và tách từ...\")\n",
    "df = pd.read_csv(clean_path)\n",
    "# Lấy cột text (sửa tên cột nếu khác)\n",
    "texts = df['comment_text'].dropna().astype(str).tolist()\n",
    "\n",
    "all_words = []\n",
    "for text in tqdm(texts, desc=\"Tokenizing\"):\n",
    "    # Clean nhẹ + Tách từ PyVi\n",
    "    words = ViTokenizer.tokenize(text.lower()).split()\n",
    "    all_words.extend(words)\n",
    "\n",
    "# 2. Tính toán độ phủ\n",
    "word_counts = Counter(all_words)\n",
    "total_occurrences = len(all_words)\n",
    "sorted_words = word_counts.most_common()\n",
    "\n",
    "current_sum = 0\n",
    "checkpoints = [100, 200, 500, 1000, 2000] # Các mốc muốn kiểm tra\n",
    "\n",
    "print(f\"\\n{'Top N từ':<10} | {'Độ phủ (%)':<15}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, (word, count) in enumerate(sorted_words):\n",
    "    current_sum += count\n",
    "    rank = i + 1\n",
    "    if rank in checkpoints:\n",
    "        percent = (current_sum / total_occurrences) * 100\n",
    "        print(f\"{rank:<10} | {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a66c7",
   "metadata": {},
   "source": [
    "## Cell 4: \n",
    "**Nhận xét**: Dựa trên bảng thống kê trên, nhóm nhận thấy tại ngưỡng Top 500, độ phủ từ vựng đã đạt mức bão hòa (~72%). Việc mở rộng thêm không mang lại hiệu quả đáng kể so với chi phí xử lý. \n",
    "\n",
    "=> **Quyết định**: Chọn ngưỡng cắt Top 500 để trích xuất ứng viên Teencode và Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c008a",
   "metadata": {},
   "source": [
    "## Cell 5: \n",
    "Xuất file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8d6880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đang xuất file với ngưỡng cắt: Top 500...\n",
      "Đã xuất: candidates_stopwords.csv\n",
      "Đã xuất: candidates_teencode.csv\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 500  # Ngưỡng cắt cho từ điển\n",
    "OUTPUT_FOLDER = '../data/dictionaries/'\n",
    "if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "print(f\"\\nĐang xuất file với ngưỡng cắt: Top {TOP_N}...\")\n",
    "\n",
    "# 1. Xuất file STOPWORDS (Lấy thẳng Top N từ xuất hiện nhiều nhất)\n",
    "# Lý thuyết Zipf: Những từ xuất hiện nhiều nhất thường là hư từ\n",
    "df_stop = pd.DataFrame(sorted_words[:TOP_N], columns=['Word', 'Frequency'])\n",
    "df_stop.to_csv(os.path.join(OUTPUT_FOLDER, 'candidates_stopwords.csv'), index=False, encoding='utf-8-sig')\n",
    "print(\"Đã xuất: candidates_stopwords.csv\")\n",
    "\n",
    "# 2. Xuất file TEENCODE (Lọc từ danh sách từ vựng, ưu tiên từ phổ biến)\n",
    "vowels = set(\"aáàảãạăắằẳẵặâấầẩẫậeéèẻẽẹêếềểễệiíìỉĩịoóòỏõọôốồổỗộơớờởỡợuúùủũụưứừửữựyýỳỷỹỵ\")\n",
    "potential_teencode = []\n",
    "\n",
    "# Chỉ quét trong những từ đã xuất hiện (sorted_words)\n",
    "for word, freq in sorted_words:\n",
    "    if '_' in word: continue # Bỏ qua từ ghép chuẩn (học_sinh)\n",
    "    \n",
    "    # Luật 1: Từ ngắn (<3 ký tự) xuất hiện nhiều (k, ko, dc...)\n",
    "    rule_short = (len(word) < 3 and freq > 10)\n",
    "    # Luật 2: Từ không có nguyên âm (tr, bt, cmn...)\n",
    "    rule_no_vowel = (not any(c in vowels for c in word) and word.isalpha())\n",
    "    # Luật 3: Từ chứa số (k4, q3...)\n",
    "    rule_has_num = (any(c.isdigit() for c in word) and not word.isdigit())\n",
    "\n",
    "    if rule_short or rule_no_vowel or rule_has_num:\n",
    "        potential_teencode.append((word, freq))\n",
    "\n",
    "# Cắt lấy đúng Top N teencode \n",
    "df_teen = pd.DataFrame(potential_teencode, columns=['Word', 'Frequency'])\n",
    "df_teen = df_teen.head(TOP_N) \n",
    "df_teen.to_csv(os.path.join(OUTPUT_FOLDER, 'candidates_teencode.csv'), index=False, encoding='utf-8-sig')\n",
    "print(\"Đã xuất: candidates_teencode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe80484",
   "metadata": {},
   "source": [
    "## Cell 6: Step 2 – Rule-based Mining (Teencode ẩn)\n",
    "\n",
    "**Vấn đề**: Phương pháp thống kê tần suất (Step 1) có thể bỏ sót các teencode \"ẩn\" chứa ký tự đặc biệt hoặc số, ví dụ: `chao2`, `haizzz`.\n",
    "\n",
    "**Giải pháp**: Nhóm đã sử dụng công cụ **Rule-based Mining** được đóng gói trong `src/step2_rule_based_mining.py` để quét lại dữ liệu và trích xuất các từ teencode tiềm năng.  \n",
    "- Tool này chạy độc lập từ terminal/IDE, đọc dữ liệu sạch `dataset_filtered.csv` và xuất kết quả `teencode_candidates_step2.csv`.\n",
    "- Trong notebook, chỉ ghi nhận bước này mà không cần gọi code.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
